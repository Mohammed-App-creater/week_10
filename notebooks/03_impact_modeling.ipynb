{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 3: Financial Inclusion Impact Modeling\n",
                "\n",
                "## Objective\n",
                "Model how events (policies, product launches, infrastructure investments) affect Ethiopiaâ€™s financial inclusion indicators, producing an **Event-Indicator Association Matrix** for forecasting.\n",
                "\n",
                "## Methodology\n",
                "- **Functional Form**: Ramped Step Function (Permanent structural changes with adoption lag).\n",
                "- **Impact Logic**: `Effect = Direction * Magnitude * AdoptionCurve(t - Lag)`.\n",
                "- **Aggregation**: Additive combination of concurrent events.\n",
                "- **Goal**: Structured impact reasoning, not causal proof."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from datetime import timedelta, datetime\n",
                "\n",
                "# Set style\n",
                "sns.set_theme(style=\"whitegrid\")\n",
                "plt.rcParams['figure.figsize'] = (12, 6)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Load Data\n",
                "Loading the enriched unified data which contains Observations, Events, and impact links (linked via `parent_id`)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load data\n",
                "df = pd.read_csv('../data/raw/ethiopia_fi_unified_data.csv')\n",
                "\n",
                "# Parse dates\n",
                "date_cols = ['observation_date', 'period_start', 'period_end']\n",
                "for col in date_cols:\n",
                "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
                "\n",
                "# Separate records types\n",
                "events = df[df['record_type'] == 'event'].copy()\n",
                "impact_links = df[df['record_type'] == 'impact_link'].copy()\n",
                "observations = df[df['record_type'] == 'observation'].copy()\n",
                "\n",
                "print(f\"Events: {len(events)}\")\n",
                "print(f\"Impact Links: {len(impact_links)}\")\n",
                "print(f\"Observations: {len(observations)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Define Impact Functions\n",
                "\n",
                "We model most events as **Ramped Step Functions**:\n",
                "1.  **Shock**: Event occurs at $T_{event}$.\n",
                "2.  **Lag**: Impact starts at $T_{start} = T_{event} + Lag$.\n",
                "3.  **Ramp**: Impact grows linearly (or logistically) from 0% to 100% over a `ramp_period` (default 6 months).\n",
                "4.  **Plateau**: Impact stays at 100% of the estimated magnitude (structural shift)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_ramp_factor(current_date, start_date, ramp_months=6):\n",
                "    \"\"\"\n",
                "    Calculates a linear ramp factor (0.0 to 1.0) based on time elapsed since start_date.\n",
                "    \"\"\"\n",
                "    if current_date < start_date:\n",
                "        return 0.0\n",
                "    \n",
                "    days_elapsed = (current_date - start_date).days\n",
                "    ramp_days = ramp_months * 30\n",
                "    \n",
                "    if days_elapsed >= ramp_days:\n",
                "        return 1.0\n",
                "    \n",
                "    return days_elapsed / ramp_days\n",
                "\n",
                "def get_magnitude_numeric(magnitude_str, default_high=0.2, default_med=0.1, default_low=0.05):\n",
                "    \"\"\"\n",
                "    Converts qualitative magnitude labels to numeric factors (percentage change assumption).\n",
                "    These defaults are placeholders and should be overridden by 'impact_estimate' if available.\n",
                "    \"\"\"\n",
                "    mapping = {\n",
                "        'high': default_high,      # e.g., 20% impact\n",
                "        'medium': default_med,     # e.g., 10% impact\n",
                "        'low': default_low,        # e.g., 5% impact\n",
                "        'negligible': 0.01\n",
                "    }\n",
                "    return mapping.get(str(magnitude_str).lower(), 0.0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Map Events to Impacts\n",
                "\n",
                "Process each `impact_link` to generate an effect series.\n",
                "\n",
                "**Logic:**\n",
                "- Iterate through `impact_links`.\n",
                "- Find corresponding `event` (via `parent_id` matching `event` `record_id`... wait, `impact_link` has `parent_id` pointing to event? Let's check schema. Actually `impact_link` schema in `reference_codes` says links via `parent_id`. But looking at the CSV data in Step 1, `impact_links` (rows 52, 53) have `parent_id` as the LAST column pointing to `EVT_...`. Correct.\n",
                "- Determine Magnitude:\n",
                "    - Use `impact_estimate` (numeric) if valid.\n",
                "    - Else fall back to `impact_magnitude` (categorical) converted to numeric.\n",
                "- Determine Direction:\n",
                "    - `increase` (+1), `decrease` (-1).\n",
                "- Calculate Effect Time Series (Monthly from 2020 to 2030)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate a monthly timeline for modeling\n",
                "timeline = pd.date_range(start='2020-01-01', end='2030-12-31', freq='ME')\n",
                "modeling_df = pd.DataFrame({'date': timeline})\n",
                "\n",
                "impact_effects = []\n",
                "\n",
                "for idx, link in impact_links.iterrows():\n",
                "    # 1. Get Event Info\n",
                "    event_id = link['parent_id']\n",
                "    event_row = events[events['record_id'] == event_id]\n",
                "    \n",
                "    if event_row.empty:\n",
                "        # Handle case where link points to non-existent event or mismatched ID\n",
                "        # In the provided CSV snippet, impact_links reference EVT_FX_LIBERAL and EVT_MELA_LAUNCH\n",
                "        # But EVT_FX_LIBERAL matches EVT_ENR_001? \n",
                "        # Actually, let's look at the data snippet again.\n",
                "        # Row 50: EVT_ENR_001 ... EVT_FX_LIBERAL (in indicator_code?? No, wait)\n",
                "        # Row 52: LNK_ENR_001 ... parent_id = EVT_FX_LIBERAL. \n",
                "        # Ah, the `parent_id` column in `impact_link` seems to refer to the `indicator_code` (e.g. EVT_FX_LIBERAL) \n",
                "        # OR the `record_id`? \n",
                "        # In standard normalization, it should match `record_id`.\n",
                "        # Let's support matching on `indicator_code` (which seems to be used as an alias ID) or `record_id`.\n",
                "        \n",
                "        # Try matching record_id\n",
                "        event_row = events[events['record_id'] == event_id]\n",
                "        if event_row.empty:\n",
                "            # Try matching indicator_code (which holds the human-readable ID like EVT_TELEBIRR)\n",
                "            event_row = events[events['indicator_code'] == event_id]\n",
                "            \n",
                "    if event_row.empty:\n",
                "        print(f\"Warning: Event {event_id} not found for Link {link['record_id']}\")\n",
                "        continue\n",
                "        \n",
                "    event = event_row.iloc[0]\n",
                "    event_date = event['observation_date']\n",
                "    if pd.isna(event_date):\n",
                "        continue\n",
                "\n",
                "    # 2. Determine Parameters\n",
                "    indicator_target = link['indicator'] # The code, e.g., ACC_OWNERSHIP\n",
                "    \n",
                "    # Direction\n",
                "    direction_map = {'increase': 1, 'decrease': -1, 'stabilize': 0, 'mixed': 0}\n",
                "    direction = direction_map.get(link.get('impact_direction', 'increase'), 1)\n",
                "    \n",
                "    # Magnitude (Use direct estimate if available, else heuristic map)\n",
                "    if pd.notna(link.get('impact_estimate')):\n",
                "        magnitude = float(link['impact_estimate'])\n",
                "    else:\n",
                "        magnitude = get_magnitude_numeric(link.get('impact_magnitude'))\n",
                "\n",
                "    # Lag\n",
                "    lag_months = float(link['lag_months']) if pd.notna(link.get('lag_months')) else 0\n",
                "    start_date = event_date + timedelta(days=lag_months*30)\n",
                "    \n",
                "    # 3. Calculate Series\n",
                "    # We want a series aligned with 'timeline'\n",
                "    # Effect = Direction * Magnitude * RampFactor\n",
                "    \n",
                "    series_name = f\"{event['indicator_code']}_on_{indicator_target}\"\n",
                "    \n",
                "    col_values = []\n",
                "    for t in timeline:\n",
                "        factor = calculate_ramp_factor(t, start_date)\n",
                "        val = direction * magnitude * factor\n",
                "        col_values.append(val)\n",
                "        \n",
                "    modeling_df[series_name] = col_values\n",
                "    \n",
                "    impact_effects.append({\n",
                "        'event_name': event.get('indicator', 'Unknown Event'),\n",
                "        'event_code': event['indicator_code'],\n",
                "        'target_indicator': indicator_target,\n",
                "        'magnitude': magnitude,\n",
                "        'direction': direction,\n",
                "        'lag_months': lag_months,\n",
                "        'series_name': series_name\n",
                "    })\n",
                "\n",
                "print(\" Modeled effects for:\")\n",
                "pd.DataFrame(impact_effects)[['event_code', 'target_indicator', 'magnitude', 'direction']]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Aggregation and Matrix Construction\n",
                "\n",
                "We now sum the effects per indicator to see the **Total Event-Driven Impact**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Group effects by target indicator\n",
                "indicators = list(set([x['target_indicator'] for x in impact_effects]))\n",
                "\n",
                "composite_effects = pd.DataFrame({'date': timeline})\n",
                "\n",
                "for ind in indicators:\n",
                "    # Find all columns for this indicator\n",
                "    relevant_cols = [x['series_name'] for x in impact_effects if x['target_indicator'] == ind]\n",
                "    if relevant_cols:\n",
                "        composite_effects[f\"Total_Effect_{ind}\"] = modeling_df[relevant_cols].sum(axis=1)\n",
                "\n",
                "# Preview\n",
                "composite_effects.tail()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Visualization\n",
                "\n",
                "Let's visualize the rollout of these impacts over time."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_effects(indicator_code):\n",
                "    col_name = f\"Total_Effect_{indicator_code}\"\n",
                "    if col_name not in composite_effects.columns:\n",
                "        print(f\"No effects modeled for {indicator_code}\")\n",
                "        return\n",
                "        \n",
                "    plt.figure(figsize=(10, 5))\n",
                "    plt.plot(composite_effects['date'], composite_effects[col_name], label=f\"Modeled Impact: {indicator_code}\", linewidth=2.5)\n",
                "    plt.title(f\"Cumulative Event Impacts on {indicator_code}\")\n",
                "    plt.ylabel(\"Impact Magnitude (Addon)\")\n",
                "    plt.legend()\n",
                "    plt.grid(True)\n",
                "    plt.show()\n",
                "\n",
                "# Plot for Account Ownership and Digital Usage if available\n",
                "plot_effects('ACC_OWNERSHIP')\n",
                "plot_effects('USG_DIGITAL_PAY')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Create Association Matrix Artifact\n",
                "\n",
                "We need a static Event (Rows) x Indicator (Cols) matrix summarizing the **Net Magnitude**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pivot impact_effects to create the matrix\n",
                "effect_summary = pd.DataFrame(impact_effects)\n",
                "\n",
                "if not effect_summary.empty:\n",
                "    # We calculate 'Net Impact' as Direction * Magnitude\n",
                "    effect_summary['net_impact'] = effect_summary['direction'] * effect_summary['magnitude']\n",
                "    \n",
                "    matrix = effect_summary.pivot_table(\n",
                "        index='event_name', \n",
                "        columns='target_indicator', \n",
                "        values='net_impact', \n",
                "        aggfunc='sum'\n",
                "    ).fillna(0)\n",
                "    \n",
                "    # Sort cols and rows for readability if needed\n",
                "    print(matrix)\n",
                "    \n",
                "    # Save\n",
                "    matrix.to_csv('../data/processed/event_indicator_matrix.csv')\n",
                "    print(\"\\nMatrix saved to ../data/processed/event_indicator_matrix.csv\")\n",
                "else:\n",
                "    print(\"No effects to populate matrix.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}